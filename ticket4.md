# Билет 4
## Страничная адресация

Механизм страничной адресации сделал ненужной ldt, рассмотрим его. 

Недостатком сегментной адресации было то, что указатель - это не число, а пара чисел. В винде активно  использовался механизм сегментной адресации. Было 2 типа, *__near && *__far  - 2 типа указателей. и было, соотв. 2 типа выделителей памяти - для каждого типа указателей. С сегментной адресацией трудно сделать файл подкачки, потому что нужно сбрасывать в файл все сегменты. Т.е. сегментная адресация

Страничная аддр - для каждой программы говорим, что она имеет 4 гб памяти. И какие-то страницы доступны, а какие-то - нет. У другой программы другие страницы доступны. 

У физической памяти можно запросить одну страницу. 

Процессору нужно помнить, как помапаны страницы. Но и сегментная аддресация не бесплатна.

хоть страничная и менее эффективна, но есть и плюсы. Например, не важно, что память фрагментированна. Если хоть одна страница доступна, то память будет выделена.

все оси сейчас используют страничную адресацию для защиты. 

### некоторые понятия
- При обращении к памяти указывается сегмент и смещение. Сегмент - 16 бит, смещение 32 (но зависит от битности процессора). Эти 2 числа вместе называются логическим адресом. 
- Процесс перевода называется сегментацией. конечный адрес называется линейным. 
- Линейный адрес преобразуется в оффсет (32 бита). Он называется Physic offset. иногда он бывает 36 бит. такое расширение на - бита называется PAE. 36 битов - можно адресовать 64 гигабайта, 32 - 4 гб. 64 гб получается как раз за счёт PAE. 

страничная адресация позволяет сделать вид, что у каждой программы своё адресное пространство. 

адресное пространство программы (из 4 гб) нарезается на страницы по 4 кб. 

есть физическая память, которая тоже мысленно делится на страницы. Ещё физической памяти может быть меньше. 

Страничная адресация позволяет каждой странице любой программы назначить страницу в физической памяти. (помапать). Т.е. если сегментная адресация позволяла взять сегмент и сказать, где его границы, а страничная адресация даёт больше гибкости, позволяя перетасовывать страницы как угодно. 

Если физической страницы нет, то управление передаётся операционной системе. Иногда операционная система может в таком случае завершить программу. 

Как устроенна штука, которая позволяет мапать? Что нужно хранить для каждого процесса? Для каждой его страницы нужно хранить, куда она ссылается. Вроде бы, можно это сделать при помоще массива из 1000000 элементов, где индекс - это виртуальная, а значение - это физический адрес.

на самом деле так и делают. используют массив. Про страницу хранится также дополнительная страница. Например, некоторые страницы могут быть помечены как рид онли.

проблема такого массива в том, что если адрес занимает 4 байта, то массив будет 4 мб. А раньше это было сопоставимо с объёмом памяти.  

Выходит, что такой массив не клёво использовать. Но суть в том, что редкая программа использует все свои 4 гб и куча страниц не используется. Что сделали интел? 1000 массивов на 1000 элементов.  Точнее, элемент массива ссылается либо на страницу, либо на другой массив на 1000 элементов. Экономия памяти в том, что в каталоге страниц можно поставить пометку о недоступности, если вся таблица страниц недоступна. 

каталог страниц и таблица страниц.

таблиц страниц много

для каждого процесса заводится такая структура. 

одна таблица страниц характеризует 4 мб. Т.е. если в процессе в адресном пространстве есть дырка на 4 мб, то  можно считать, что одну таблицу страниц сэкономили.

Не вышло ли дороговато? вместо 1 обращения к памяти теперь 3. Но на самом деле это работает быстро. Во первых, сами страницы кешируются. Кроме того, интелы сделали специальный кеш для кеширования этой структуры (он называется tlb, а в mmu хранится сама структура). 
Проблема в том, что мапа для каждого процесса своя. Так что при переключении процессов нужно этот кеш сбросить. И на старых моделях так и делалось. (context swith). Он медленный из-за того, что сбрасывается этот кеш-мапа. Сейчас, возможно, сделано какое-то таггирование, чтобы этот кеш не всегда сбрасывался. Операционная система говорит теги процессору, когда нужно сбрасывать кеш. Т.е. стираются не все страницы, а частично. 

этот кеш имеет достаточно большой объём. Порядка 1000 страниц. Но если сделать случайный доступ по очень большому объёму, то обращения к памяти таки будут медленными. А если кеш не работает (кеш-мисы), то за обращение надо платить много. Но на практике такая проблема возникает очень редко (в специфичном софте). Но интел сделали оптимизацию. Пусть программа использует всю память порядка 4 гб. При таких объёмах трудно управлять маленькими кусочками по 4 кб. У интелов есть оптимизация, когда используются большие страницы (huge pages). Если стоит бит, то сразу идёт ссылка на физическую память. Т.е. будет меппинг сразу на 4 гб, но они должны быть подряд.

итог: страничная адр. позволяет либо мапать небольшое число страниц произвольно, либо большие куски, но которые идут подряд. 

### большие страницы

как выделить большие страницы? на винде есть специальный бит: выделить именно большие страницы, не пытаясь бить их на мелкие. 
В чём сложность поддержки больших страниц (в операционных системах)? Первая проблема - это при использовании файла подкачки. Такая штука всегда включена по дефолту. Допустим, что системе начало не хватать памяти. Скажем, программа выделила памяти больше, чем реально есть. В такой ситуации есть 2 варианта: либо отказать программе (что очень плохо, ведь раньше было не очень много памяти. Например, 95 винда загружалась на 4 мб), либо использовать своп-память. Если какая-то страница используется редко, то она сбрасывается на диск, а её память идёт на новое выделение. Когда старая страница снова нужна, она загружается в память снова. С большими страницами проблема, т.к. долго сбрасывать на диск.  

Т.е. большие страницы по 4мб не посвопать. что сделать, если их нужно свапать? разбить на маленькие (линукс), либо всегда держать их в памяти. В первом случае пользователь ждёт, что у него будут большие страницы, а они становятся маленькими. Во втором случае тратится ценный ресурс. Поэтому для этой операции нужны права. 

на 64 битных системах каталог страниц -- многоуровневый. Страницы по 512 элементов. Первая характеризует 2 метра, вторая - 1 гб.  Т.е. теперь память 4-уровневая. Но чтобы сделать долгое обращение - это ещё нужно постараться.

есть ещё одна вещь, связанная с 36 байтами вместо 32. Откуда ещё 4 бита? Сначала идут данные страницы, а в конце -- флаги. Исторически сложилось так, что эти битики - расширяемые. т.е. 4 бита используются просто как данные. Но на 64 битных системах это неактуально.

Когда идёт обращение к странице, которой нет, управление передаётся операционной системе. 

у всех страниц ставится запрет на запись, чтобы при любой записи управление передавалось оси и делался copy on write, который используется после fork.

Когда ещё возможно, чтобы 2 процесса ссылались на одну страницу? при mmf (memory mapped files).  

если запросить много памяти, то есть оптимизация. При обращении происходит page fault и проверка, а выделял ли процесс эту память? если выделял, то память выделяется на самом деле. 

Это важно, если делаются какие-то бенчмарки. 

[<<](https://github.com/Owntage/asm_tickets/blob/master/ticket2.md) [>>](https://github.com/Owntage/asm_tickets/blob/master/ticket5.md)
